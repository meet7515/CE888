# -*- coding: utf-8 -*-
"""Copy of pytorch fireNonFire

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AOUbwNNjBKQv8lhCEQds8IyaH8zO5Afv
"""

import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data
import torch.nn.functional as F
import torchvision
import torchvision.models as models
from torchvision import transforms
from PIL import Image
import matplotlib.pyplot as plt
import numpy as np

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !gdown --id "1gkh0-i0iBcjKyklrBWqCsyHVfwF65B16"
# !gdown --id "1Apcsj9V-XbxrpvKDC_w9CkYxS9334iXd"
# !unzip "Test.zip"
# !unzip "Training.zip"
# !rm "Training.zip"
# !rm "Test.zip"
# !rm -rf "__MACOSX"
# !rm -rf "sample_data"

import os
os.mkdir("Validation")
os.mkdir("Validation/Fire")
os.mkdir("Validation/No_Fire")
import shutil
import random
source_dir = 'Training/Fire'
target_dir = 'Validation/Fire'
file_names = os.listdir(source_dir)
validationLength=int(0.1*len(file_names))
test_list = [random.randrange(1,len(file_names)-1 , 1) for i in range(validationLength)]
res=[]
[res.append(x) for x in test_list if x not in res]
new_file_names=[]

for j in res:
  new_file_names.append(file_names[j])

for file_name in new_file_names:
    shutil.move(os.path.join(source_dir, file_name), target_dir)

source_dir = 'Training/No_Fire'
target_dir = 'Validation/No_Fire'
    
file_names = os.listdir(source_dir)

validationLength=int(0.1*len(file_names))
test_list = [random.randrange(1,len(file_names)-1 , 1) for i in range(validationLength)]
res=[]
[res.append(x) for x in test_list if x not in res]

new_file_names=[]

for j in res:
  new_file_names.append(file_names[j])

for file_name in new_file_names:
    shutil.move(os.path.join(source_dir, file_name), target_dir)

model_resnet18 = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)
model_resnet34 = torch.hub.load('pytorch/vision', 'resnet34', pretrained=True)
model_resnet50 = torch.hub.load('pytorch/vision', 'resnet50', pretrained=True)

# Freeze all params except the BatchNorm layers, as here they are trained to the
# mean and standard deviation of ImageNet and we may lose some signal
for name, param in model_resnet18.named_parameters():
    if("bn" not in name):
        param.requires_grad = False
        
for name, param in model_resnet34.named_parameters():
    if("bn" not in name):
        param.requires_grad = False

num_classes = 2

model_resnet18.fc = nn.Sequential(nn.Linear(model_resnet18.fc.in_features,512),
                                  nn.ReLU(),
                                  nn.Dropout(),
                                  nn.Linear(512, num_classes))

model_resnet34.fc = nn.Sequential(nn.Linear(model_resnet34.fc.in_features,512),
                                  nn.ReLU(),
                                  nn.Dropout(),
                                  nn.Linear(512, num_classes))

def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=5, device="cpu"):
    
    for epoch in range(epochs):
        training_loss = 0.0
        valid_loss = 0.0
        model.train()
        for batch in train_loader:
            optimizer.zero_grad()
            inputs, targets = batch
            inputs = inputs.to(device)
            targets = targets.to(device)
            output = model(inputs)
            loss = loss_fn(output, targets)
            loss.backward()
            optimizer.step()
            training_loss += loss.data.item() * inputs.size(0)
        training_loss /= len(train_loader.dataset)
        
        model.eval()
        num_correct = 0 
        num_examples = 0
        for batch in val_loader:
            inputs, targets = batch
            inputs = inputs.to(device)
            output = model(inputs)
            targets = targets.to(device)
            loss = loss_fn(output,targets) 
            valid_loss += loss.data.item() * inputs.size(0)
                        
            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets).view(-1)
            num_correct += torch.sum(correct).item()
            num_examples += correct.shape[0]
        valid_loss /= len(val_loader.dataset)
        print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}, accuracy = {:.4f}'.format(epoch, training_loss,
        valid_loss, num_correct / num_examples))

batch_size=32
img_dimensions = 224

# Normalize to the ImageNet mean and standard deviation
# Could calculate it for the cats/dogs data set, but the ImageNet
# values give acceptable results here.
img_transforms = transforms.Compose([

    transforms.Resize((img_dimensions, img_dimensions)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] )

    ])

img_test_transforms = transforms.Compose([

    transforms.Resize((img_dimensions, img_dimensions)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225] ),

    ])

def check_image(path):
    try:
        im = Image.open(path)
        return True
    except:
        return False

train_data_path = "/content/Training"
train_data = torchvision.datasets.ImageFolder(root=train_data_path,transform=img_transforms, is_valid_file=check_image)

validation_data_path = "/content/Validation"
validation_data = torchvision.datasets.ImageFolder(root=validation_data_path,transform=img_test_transforms, is_valid_file=check_image)

test_data_path = "/content/Test"
test_data = torchvision.datasets.ImageFolder(root=test_data_path,transform=img_test_transforms, is_valid_file=check_image)

num_workers = 2
train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers)
validation_data_loader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)
test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)


if torch.cuda.is_available():
    device = torch.device("cuda") 
else:
    device = torch.device("cpu")

print(f'Num training images: {len(train_data_loader.dataset)}')
print(f'Num validation images: {len(validation_data_loader.dataset)}')
print(f'Num test images: {len(test_data_loader.dataset)}')

import seaborn as sns

def test_model(model,data_loader):
    correct = 0
    total = 0
    nb_classes=2
    confusion_matrix = torch.zeros(nb_classes, nb_classes)
    with torch.no_grad():
        for data in data_loader:
            images, labels = data[0].to(device), data[1].to(device)
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            for t, p in zip(labels.view(-1), predicted.view(-1)):
                confusion_matrix[t.long(), p.long()] += 1



    cf_matrix=confusion_matrix

    
    sns.heatmap(cf_matrix, annot=True, annot_kws={"size": 16},fmt='g')

    print("================Accuracy according to the Confusion matrix is============== \n")
    classAccuracy=confusion_matrix.diag()/confusion_matrix.sum(1)
    print(f"Fire predicted correct accuracy is {classAccuracy[0]}\n")
    print(f"No_Fire predicted correct accuracy is {classAccuracy[1]}\n")
    cf = confusion_matrix.numpy()
    print(f"Total Accuracy is {np.trace(cf) / float(np.sum(cf))}\n")
    precision = cf[1,1] / sum(cf[:,1])
    recall    = cf[1,1] / sum(cf[1,:])
    f1_score  = 2*precision*recall / (precision + recall)
    print(f"Precision is {precision}\n")
    print(f"Recall is {recall}\n")
    print(f"F1_Score is {f1_score}\n")
    print("================Confusion matrix is============== \n")
    print("================0 is Fire and 1 is No_Fire============== \n")



    return cf

model_resnet18.to(device)
optimizer = optim.Adam(model_resnet18.parameters(), lr=0.001)
train(model_resnet18, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, validation_data_loader, epochs=4, device=device)



#test accuracy
print("==================For Test==================\n")
cf_test = test_model(model_resnet18,test_data_loader)

# #train accuracy
# print("==================For Train==================\n")
# cf_train= test_model(model_resnet18,train_data_loader)

# #validation accuracy
# print("==================For Validation==================\n")

# cf_validation= test_model(model_resnet18,validation_data_loader)





model_resnet34.to(device)
optimizer = optim.Adam(model_resnet34.parameters(), lr=0.001)
train(model_resnet34, optimizer, torch.nn.CrossEntropyLoss(), train_data_loader, validation_data_loader, epochs=4, device=device)

#test accuracy
print("==================For Test==================\n")
cf_test = test_model(model_resnet34,test_data_loader)

#train accuracy
print("==================For Train==================\n")

cf_train= test_model(model_resnet34,train_data_loader)

#validation accuracy
print("==================For Validation==================\n")

cf_validation= test_model(model_resnet34,validation_data_loader)